# -*- coding: utf-8 -*-
"""Symptom_predictor_without_context.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XAYukoqrm1Mlql8f4fbbYKIQcR8X___7
"""

from google.colab import drive
drive.mount('/content/drive')

import matplotlib.pyplot as plt
import os
import tensorflow as tf
import matplotlib
matplotlib.style.use('ggplot')
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.metrics import confusion_matrix
import seaborn as sns
from keras.applications.vgg19 import preprocess_input
from keras.models import Model
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import Dropout
from keras.applications.inception_v3 import InceptionV3
from keras.callbacks import EarlyStopping
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras import layers, regularizers

IMAGE_SHAPE = (224, 224)
TRAINING_DATA_DIR = '/content/drive/MyDrive/final_ee_data2/train'
VALID_DATA_DIR = '/content/drive/MyDrive/final_ee_data2/test'

datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function = preprocess_input,
    
    
    validation_split=0.1
)
train_generator = datagen.flow_from_directory(
    TRAINING_DATA_DIR,
    shuffle=True,
    target_size=IMAGE_SHAPE,
    
)
valid_generator=datagen.flow_from_directory(TRAINING_DATA_DIR,target_size=(224,224),subset='validation',batch_size = 32)

test_generator = datagen.flow_from_directory(
    VALID_DATA_DIR,
    shuffle=False,
    target_size=IMAGE_SHAPE,
)

label_map = (train_generator.class_indices)
print(label_map)

model = VGG19(include_top = False,input_shape=(224,224,3),weights = 'imagenet')
model.trainable = False
# model.add(tf.keras.layers.GlobalMaxPooling2D())
conv1 = tf.keras.layers.Conv2D(1024,3,1,'valid',activation='relu',kernel_regularizer = regularizers.l2(0.01))(model.layers[-1].output)
conv2 = tf.keras.layers.Conv2D(512,2,1,'valid',activation='relu',kernel_regularizer = regularizers.l2(0.01))(conv1)
conv3 = tf.keras.layers.Conv2D(512,2,2,'valid',activation='relu',kernel_regularizer = regularizers.l2(0.01))(conv2)
gmax = tf.keras.layers.GlobalMaxPooling2D()(conv3)
flat1 = Flatten()(gmax)
class1 = Dense(512, activation='relu')(flat1)
output = Dense(17, activation='softmax')(class1)
# define new model
model = Model(inputs=model.inputs, outputs=output)
model.summary()

model.compile(
    optimizer=tf.keras.optimizers.Adam(lr=0.0001),
    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)
# print(model.summary())

from keras.callbacks import ModelCheckpoint
from datetime import datetime

EPOCHS = 15
BATCH_SIZE = 32
checkpoint = ModelCheckpoint(filepath = '/content/drive/MyDrive/final_models/Checkpoint-{epoch:02d}-{val_accuracy:.02f}.h5',verbose=1,save_best_only=True,monitor = 'val_loss',mode = 'min')
callbacks = [checkpoint]
callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
history = model.fit(train_generator,
                    steps_per_epoch=train_generator.samples // BATCH_SIZE,
                    epochs=EPOCHS,
                    validation_data=valid_generator,
                    validation_steps= valid_generator.samples // BATCH_SIZE,
                    callbacks = callbacks,
                    verbose=1
                    )

model1 = tf.keras.models.load_model('/content/drive/MyDrive/final_model_1/symptom_classifier_81.11.h5')

print(model1.summary())

model1.evaluate(test_generator)

x = test_generator.class_indices

print(len(x))

import sklearn.metrics

predictions_valid = model1.predict(test_generator)

y_pred = []

for i in range(0,len(predictions_valid)):
    y_pred = y_pred + [np.argmax(predictions_valid[i])]

print('predictions : ',y_pred)
y_true = test_generator.classes
print('true classes:',y_true)

score = accuracy_score(y_true, y_pred)
print('Classification Report: ',classification_report(y_true,y_pred))
cm = confusion_matrix(y_true, y_pred)
f,ax= plt.subplots(figsize=(15, 15))
sns.heatmap(cm, fmt='g', ax=ax); #annot=True to annotate cells, ftm='g' to disable scientific notation

# labels, title and ticks
ax.set_xlabel('Predicted labels',fontsize = 28);ax.set_ylabel('True labels',fontsize = 28);
ax.set_title('Confusion Matrix');
classes_rev = []
classes = ['Swollen eye',  'Mouth ulcer',  'Skin dryness',  'Neck swelling',  'Skin irritation', 'Swollen tonsils', 'Knee swelling', 'Redness in ear', 'Dry scalp', 'Skin rash', 
           'Itchy eyelid', 'Hand lump', 'Skin growth', 'Eye redness', 'Foot swelling', 'Lip swelling',  'Eyelid rash']
l = 16
for i in range(1,l+1):
    classes_rev = classes_rev + [classes[l-i]]
ax.xaxis.set_ticklabels(classes,fontsize = 5, );ax.yaxis.set_ticklabels(classes, fontsize = 5);
ax.figure.savefig("hybrid_cnn.png")
print('Accuracy: ', score)
print('F1',sklearn.metrics.f1_score(y_true, y_pred, average='weighted'))