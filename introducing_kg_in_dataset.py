# -*- coding: utf-8 -*-
"""introducing_kg_in_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k_deOUqi0iSxPGkDrhXPLvDNv3I7A9X9
"""

import pickle 
import json
import pandas as pd
import re

with open(r"/content/drive/MyDrive/AAAI work/knowledge graph/SD++.p", "rb") as input_file:
  kg = pickle.load(input_file)

#removing disease keys
for i in list(kg.keys()):
  if 'D' in i:
    kg.pop(i)

#sorting according to coorelation value
for i in list(kg.keys()):
  kg[i] = sorted(kg[i].items(), key=lambda x: x[1], reverse=True)

tmp_lst=[]
lst=[]

for i in kg.keys():
  for j in range(len(kg[i])):
    tmp_lst.append([i,kg[i][j][0],kg[i][j][1]])
  lst.append(tmp_lst)

  tmp_lst=[]

t=[]
r=[]
count=0
for i, samples in enumerate(lst):
  for j, k in enumerate(samples):
    if 'S' in k[1] and count<3:
      r.append(k)
      count=count+1
  t.append(r)
  r=[]
  count=0
top_symptom = t

t=[]
r=[]
count=0
for i, samples in enumerate(lst):
  for j, k in enumerate(samples):
    if 'D' in k[1] and count<3:
      r.append(k)
      count=count+1
  t.append(r)
  r=[]
  count=0
top_disease = t

with open(r"/content/drive/MyDrive/AAAI work/Disease and symptom mapping/IDD.p", "rb") as input_file:
  disease_mapping = pickle.load(input_file)

with open(r"/content/drive/MyDrive/AAAI work/Disease and symptom mapping/IDS.p", "rb") as input_file:
  symptom_mapping = pickle.load(input_file)

for i, tup in enumerate(top_symptom):
  for j, k in enumerate(tup):
    top_symptom[i][j][1] = symptom_mapping[top_symptom[i][j][1]]
    top_symptom[i][j][0] = symptom_mapping[top_symptom[i][j][0]]
    top_disease[i][j][1] = disease_mapping[top_disease[i][j][1]]
    top_disease[i][j][0] = symptom_mapping[top_disease[i][j][0]]

tmp_slist=[]
tmp_dlist=[]

kgs={0:0}
kgd={0:0}

for i in range(len(top_symptom)):
  for j in range(3):
    tmp_slist.append(top_symptom[i][j][1:2])
    tmp_dlist.append(top_disease[i][j][1:2])

  kgs[top_symptom[i][0][0]] = tmp_slist
  kgd[top_disease[i][0][0]] = tmp_dlist

  tmp_slist=[]
  tmp_dlist=[]

kgs.pop(0)
kgd.pop(0)

for i in kgs.keys():
  string ='[S] ' + kgs[i][0][0] + ' ' + kgs[i][1][0] + ' ' +  kgs[i][2][0] + ' [D] ' + kgd[i][0][0] + ' ' + kgd[i][1][0] + ' ' + kgd[i][2][0]
  kgs[i] = string

symptoms_names=list(set(list(kgs.keys())))

file_name='new_file_89'
f = open(file_name+'.json')
data = json.load(f)
train_data=data['train']
test_data=data['test']

for i, samples in enumerate(train_data):
  for j, utterance in enumerate(samples['Dialogues']):
    if j==0:
      for s_names in symptoms_names:
        if s_names.lower() in utterance.lower():
          train_data[i]['Dialogues'][j] = train_data[i]['Dialogues'][j] + ' [KG] ' + kgs[s_names]

for i, samples in enumerate(test_data):
  for j, utterance in enumerate(samples['Dialogues']):
    if j==0:
      for s_names in symptoms_names:
        if s_names.lower() in utterance.lower():
          test_data[i]['Dialogues'][j] = test_data[i]['Dialogues'][j] + ' [KG] ' + kgs[s_names]

for i in range(len(train_data)):
  if train_data[i]['Dialogues'][0] == 'I do not know':
    train_data[i]['Dialogues'][0] = 'I do not know' + ' [KG] Blank '

for i in range(len(test_data)):
  if test_data[i]['Dialogues'][0] == 'I do not know':
    test_data[i]['Dialogues'][0] = 'I do not know' + ' [KG] Blank '

datasets={'train':train_data,'test':test_data}

with open(file_name+ '_kg.json', "w") as outfile:
    json.dump(datasets, outfile)







