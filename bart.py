# -*- coding: utf-8 -*-
"""BART.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16pwYjDkAISp9VDyu5YAuyZWUzYBDu-kJ
"""

!pip install simpletransformers

#!pip install tensorflow_text
#import tensorflow_text as text
import pandas as pd
import numpy as np
import keras
import tensorflow as tf
from keras.layers import *
import tensorflow_hub as hub
from keras.models import Model
from sklearn.model_selection import train_test_split
import pandas as pd
from simpletransformers.seq2seq import Seq2SeqModel,Seq2SeqArgs
import json

model_args = Seq2SeqArgs()
model_args.num_train_epochs = 3
model_args.no_save = True
model_args.evaluate_generated_text = True
model_args.evaluate_during_training = True
model_args.evaluate_during_training_verbose = True
model_args.max_length=128

# Initialize model
model = Seq2SeqModel(encoder_decoder_type="bart", encoder_decoder_name="facebook/bart-large", args=model_args, use_cuda=True, max_length=200)

# Training set preparation
f = open('dataset.json')
data = json.load(f)
train_data=data['train']
test_data=data['test']

input=[]
output=[]
tmp_input=''
for i in range(len(train_data)):
  for j in range(len(train_data[i]['Dialogues'])):
    tmp_input = tmp_input + train_data[i]['Dialogues'][j] + ' [EOS] '
    if j%2==0:
      input.append(tmp_input.strip())
      output.append(train_data[i]['Dialogues'][j+1])
  tmp_input=''

trn_df = pd.DataFrame(list(zip(output, input)),
               columns =['output', 'input'])


input=[]
output=[]
tmp_input=''
for i in range(len(test_data)):
  for j in range(len(test_data[i]['Dialogues'])):
    tmp_input = tmp_input + test_data[i]['Dialogues'][j] + ' [EOS] '
    if j%2==0:
      input.append(tmp_input.strip())
      output.append(test_data[i]['Dialogues'][j+1])
  tmp_input=''

val_df = pd.DataFrame(list(zip(output, input)),
               columns =['output', 'input'])

trn_df.columns = ['target_text', 'input_text']
val_df.columns = ['target_text', 'input_text']

# Train the model
model.train_model(trn_df, eval_data=val_df)

val_df = val_df.reset_index()
generated=[]
actual=[]
patient_dialogue=[]
for i in range(len(val_df)):
  actual.append(val_df['target_text'][i])
  patient_dialogue.append(val_df['input_text'][i])
  pred = model.predict([val_df['input_text'][i]])[0]
  #print(pred)
  #print(val_df['target_text'][i])
  generated.append(pred)
  #print(i)

new = pd.DataFrame(list(zip(patient_dialogue, actual, generated)),
               columns =['Input text', 'Actual', 'Generated'])

!pip -q install transformers==2.9.0 gdown
!pip install rouge
!pip install evaluate
!pip install bert_score

from nltk.translate.meteor_score import meteor_score
from evaluate import load
from rouge import Rouge
from nltk.translate.bleu_score import sentence_bleu
import evaluate
bertscore = load("bertscore")
meteor = evaluate.load('meteor')
  
rouge = Rouge()
bert_scores=0
one_gram=0
two_gram=0
three_gram=0
four_gram=0
rouge_1=0
rouge_2=0
rouge_l=0
meteor_score=0

df = new

for i in range(len(df)):
  predictions = df['Generated'][i]
  references  = df['Actual'][i]

  #for bert score
  #bert_scores = bert_scores+ bertscore.compute(predictions=[predictions], references=[references], model_type="distilbert-base-uncased")['f1'][0]


  #for BLEU score
  one_gram = one_gram + sentence_bleu([references.split()], predictions.split(), weights=(1, 0, 0, 0))
  two_gram = two_gram + sentence_bleu([references.split()], predictions.split(), weights=(0.5, 0.5, 0, 0))
  three_gram = three_gram + sentence_bleu([references.split()], predictions.split(), weights=(0.33, 0.33, 0.33, 0))
  four_gram = four_gram + sentence_bleu([references.split()], predictions.split(), weights=(0.25, 0.25, 0.25, 0.25))

  #for ROUGE score
  if references == '.':
    references='empty'
  rouge_scores = rouge.get_scores(predictions, references)
  rouge_1 = rouge_1 + rouge_scores[0]['rouge-1']['f']
  rouge_2 = rouge_2 + rouge_scores[0]['rouge-2']['f']
  rouge_l = rouge_l + rouge_scores[0]['rouge-l']['f']

  #for METEOR score
  meteor_score = meteor_score + meteor.compute(predictions=[predictions], references=[references])['meteor']

#print('bert_scores : ', bert_scores/len(df))
print('BLEU 1      : ', one_gram/len(df))
print('BLEU 2      : ', two_gram/len(df))
print('BLEU 3      : ', three_gram/len(df))
print('BLEU 4      : ', four_gram/len(df))
print('ROUGE 1     : ', rouge_1/len(df))
print('ROUGE 2     : ', rouge_2/len(df))
print('ROUGE L     : ', rouge_l/len(df))
print('METEOR      : ', meteor_score/len(df))

new.to_csv('BART(with real symptom).csv', index=False)

